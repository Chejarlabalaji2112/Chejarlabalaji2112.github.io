![thumbnail](../images/TBP.png)

## The “BIG” Picture
What is it we actually want? We need a system that is very Intelligent and can solve everything in the universe. This is our ultimate goal. That is why we are working on Artificial Intelligence (AI). The reason is simple: human limitations — like memory, computation, and bias — hold us back, and AI could extend what we can achieve as a species.

In my words, a robot is a computer that has actuators, can perceive the world, and can interact with the world through actuators. But what we are expecting from robots is behavior that is at least human. It should at least do all the work a human can do. Our current robots are just task-specific machines — like Roombas, robotic arms, or delivery bots — that stick to the definition. Nothing wrong in this; this is a business world where money matters. “Identify the problem and sell the solution” is what happens everywhere.

---
### Agents
An agent is an independent system that perceives its environment and takes actions to reach some goal. Insights from Society of Mind by Marvin Minsky: our mind itself has a bunch of agents that work collectively to achieve goals. Thinking of AI in this modular way may help us design more flexible and intelligent systems. In fact, much of today’s AI research already explores this idea through multi-agent systems and modular architectures, but these are still narrow and far from human-level collective intelligence.

---

### The Big Problem
We need AI to overcome human limitations: limited computational power, irrational thoughts and decision making, leaky memory, sloppy and unstable preferences, limited-precision agents, etc., and solve the big problem.

Current AI is Large Language Models (LLMs). LLMs are the best information retrievers to date, but not the AI we are expecting (my opinion). Intelligence — the ability (or capacity) to adapt under insufficient knowledge and resources — is much broader.

AI should have natural language processing, learning with understanding, learning to learn (meta-learning), reasoning, and knowledge representation (perceiving the world is common) to match our big picture. For example, LLMs show progress in NLP but are still shallow in reasoning and meta-learning.

---

### Use-Cases and Beyond
With such AI, we can solve most problems. We also want to reduce mundane work: robots and computers should handle chores, schedule our tasks, or manage files — acting as true personal assistants.

Everyone today is busy building narrow products to prove something to investors, managers, or friends. That is why we see so many narrow AIs. I call these *“artificial systems with hacks”* that mimic intelligence.

I want to see an AI which overcomes human limitations. And I also want it to handle catastrophic events (like Chernobyl, Fukushima, or Hiroshima–Nagasaki) better than humans. Unlike us, AI would not panic, could process signals faster, and simulate multiple outcomes before acting.
